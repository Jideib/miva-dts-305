{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7fa3bf-c2b4-448b-a10f-093f12bf40c6",
   "metadata": {},
   "source": [
    "# This is DTS 305 Lab work on Web Scraping from MAN-DTS M24 G2\n",
    "## Name and Matric Number\n",
    "### Ibraheem Alawode 2023/C/DSC/0169\n",
    "### Yetunde Omotayo 2023/C/DSC/0146\n",
    "### Glory Chidiogo Anekwe 2023/C?DSC/0074\n",
    "### Ajidahun Daniel 2025/A/DSC/0044\n",
    "### James Samuel 2024/B/B/DSC/0160\n",
    "### Ehiorobo Vicent Etinosa 2024/B/DSC/0569"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27466895-c99f-40f6-9f90-0670fa143eda",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ada481-71dd-40be-997e-aa985d99a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# For inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c0fef-993c-4632-ae0c-4322e392fe1f",
   "metadata": {},
   "source": [
    "### Setting the Url and testing if the site is accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9a016c-9cb0-46f4-bd55-b07b5aae0ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: http://books.toscrape.com/\n",
      "Response Status: 200\n"
     ]
    }
   ],
   "source": [
    "# Examine the website structure\n",
    "url = \"http://books.toscrape.com/\"\n",
    "print(f\"Scraping URL: {url}\")\n",
    "\n",
    "# Make a test request to see if the site is accessible\n",
    "test_response = requests.get(url, timeout=10)\n",
    "print(f\"Response Status: {test_response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb39763-dcda-4eae-b9f9-10ae96dc8fef",
   "metadata": {},
   "source": [
    "### Scraping the website with a defined function to scrape 20 books at once on the same page with specific features needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f562c2-09ef-4348-8bf1-1275a9d652f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping books from homepage...\n",
      "Successfully scraped 20 books\n"
     ]
    }
   ],
   "source": [
    "def scrape_books_from_page(url):\n",
    "    \"\"\"\n",
    "    Scrape book data from a single page\n",
    "    \"\"\"\n",
    "    books_data = []\n",
    "    \n",
    "    try:\n",
    "        # Send HTTP request\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        \n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all book containers\n",
    "        books = soup.find_all('article', class_='product_pod')\n",
    "        \n",
    "        for book in books:\n",
    "            try:\n",
    "                # Extract title\n",
    "                title_tag = book.find('h3').find('a')\n",
    "                title = title_tag.get('title', 'No Title')\n",
    "                \n",
    "                # Extract price\n",
    "                price_tag = book.find('p', class_='price_color')\n",
    "                price_text = price_tag.get_text(strip=True) if price_tag else '£0.00'\n",
    "                \n",
    "                # Extract rating\n",
    "                rating_tag = book.find('p', class_='star-rating')\n",
    "                rating_class = rating_tag.get('class', [''])[1] if rating_tag else 'Zero'\n",
    "                \n",
    "                # Extract availability\n",
    "                availability_tag = book.find('p', class_='instock availability')\n",
    "                availability = availability_tag.get_text(strip=True) if availability_tag else 'Not Available'\n",
    "                \n",
    "                books_data.append({\n",
    "                    'Title': title,\n",
    "                    'Price': price_text,\n",
    "                    'Rating': rating_class,\n",
    "                    'Availability': availability\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing a book: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error accessing {url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing page: {e}\")\n",
    "    \n",
    "    return books_data\n",
    "\n",
    "# Scrape books from the homepage\n",
    "print(\"Scraping books from homepage...\")\n",
    "books_data = scrape_books_from_page(\"http://books.toscrape.com/\")\n",
    "print(f\"Successfully scraped {len(books_data)} books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625e5aa-b4da-4b07-af27-dba07d37c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_books(max_pages=49):\n",
    "    \"\"\"\n",
    "    Scrape books from multiple pages\n",
    "    \"\"\"\n",
    "    all_books = []\n",
    "    base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    \n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        if page_num == 1:\n",
    "            url = \"http://books.toscrape.com/\"\n",
    "        else:\n",
    "            url = base_url.format(page_num)\n",
    "        \n",
    "        print(f\"Scraping page {page_num}...\")\n",
    "        page_books = scrape_books_from_page(url)\n",
    "        all_books.extend(page_books)\n",
    "        \n",
    "        # Be respectful - add a small delay\n",
    "        import time\n",
    "        time.sleep(10)  # 1 second delay between requests\n",
    "    \n",
    "    return all_books\n",
    "\n",
    "# Scrape from multiple pages (adjust max_pages as needed)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Scraping from multiple pages...\")\n",
    "all_books = scrape_all_books(max_pages=45)  \n",
    "print(f\"Total books scraped: {len(all_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3a50a-51ac-4a96-ad73-78b6dcb7cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tornado.general:Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x7f4f05e5d7b0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_books' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = pd.DataFrame(\u001b[43mall_books\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display initial data\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitial DataFrame Info:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_books' is not defined"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_books)\n",
    "\n",
    "# Display initial data\n",
    "print(\"Initial DataFrame Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Clean the data\n",
    "\n",
    "# 1. Convert prices from strings to numerical values\n",
    "def clean_price(price_str):\n",
    "    \"\"\"Extract numerical value from price string\"\"\"\n",
    "    try:\n",
    "        # Remove £ symbol and convert to float\n",
    "        price = float(re.sub(r'[^\\d.]', '', price_str))\n",
    "        return price\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "df['Price_Clean'] = df['Price'].apply(clean_price)\n",
    "\n",
    "# 2. Map ratings to numerical values\n",
    "rating_mapping = {\n",
    "    'One': 1,\n",
    "    'Two': 2,\n",
    "    'Three': 3,\n",
    "    'Four': 4,\n",
    "    'Five': 5,\n",
    "    'Zero': 0\n",
    "}\n",
    "\n",
    "df['Rating_Numeric'] = df['Rating'].map(rating_mapping)\n",
    "\n",
    "# Display cleaned data\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA AFTER CLEANING\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(f\"Min Price: £{df['Price_Clean'].min():.2f}\")\n",
    "print(f\"Max Price: £{df['Price_Clean'].max():.2f}\")\n",
    "print(f\"Mean Price: £{df['Price_Clean'].mean():.2f}\")\n",
    "print(f\"Median Price: £{df['Price_Clean'].median():.2f}\")\n",
    "\n",
    "print(\"\\nRating Distribution:\")\n",
    "print(df['Rating_Numeric'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fc919-8260-4d90-9b1a-f1ba053d865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "\n",
    "# 1. Categorize books as \"Affordable\" or \"Expensive\"\n",
    "df['Price_Category'] = pd.cut(df['Price_Clean'],\n",
    "                               bins=[0, 20, float('inf')],\n",
    "                               labels=['Affordable', 'Expensive'])\n",
    "\n",
    "# 2. Check if we have any NaN in Price_Category\n",
    "print(f\"Books with undefined price category: {df['Price_Category'].isna().sum()}\")\n",
    "\n",
    "# 3. Calculate average rating for each category\n",
    "avg_ratings = df.groupby('Price_Category')['Rating_Numeric'].mean()\n",
    "print(\"\\nAverage Ratings by Price Category:\")\n",
    "print(avg_ratings)\n",
    "\n",
    "# 4. Create a feature for title length (additional feature)\n",
    "df['Title_Length'] = df['Title'].apply(len)\n",
    "\n",
    "# 5. Create a feature for availability status (boolean)\n",
    "df['In_Stock'] = df['Availability'].str.contains('In stock', case=False, na=False)\n",
    "\n",
    "# Display the engineered features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENGINEERED FEATURES\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nPrice Category Distribution:\")\n",
    "print(df['Price_Category'].value_counts())\n",
    "print(\"\\nIn Stock Status:\")\n",
    "print(df['In_Stock'].value_counts())\n",
    "print(\"\\nFirst 5 rows with new features:\")\n",
    "print(df[['Title', 'Price_Clean', 'Price_Category', 'Rating_Numeric', 'Title_Length', 'In_Stock']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfba42-5d8a-4685-ab5f-f47f68310acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "\n",
    "# Set figure size for all plots\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# 1. Pie chart showing proportion of affordable vs expensive books\n",
    "plt.figure(figsize=(10, 6))\n",
    "price_counts = df['Price_Category'].value_counts()\n",
    "colors = ['#66c2a5', '#fc8d62']  # Green for Affordable, Orange for Expensive\n",
    "plt.pie(price_counts.values, labels=price_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90, explode=(0.05, 0), shadow=True)\n",
    "plt.title('Proportion of Affordable vs Expensive Books', fontsize=16, fontweight='bold')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Bar chart of average ratings by category\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_ratings_plot = df.groupby('Price_Category')['Rating_Numeric'].mean().sort_index()\n",
    "bars = plt.bar(avg_ratings_plot.index, avg_ratings_plot.values, \n",
    "               color=['#66c2a5', '#fc8d62'], edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar, value in zip(bars, avg_ratings_plot.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "             f'{value:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.title('Average Ratings by Price Category', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Price Category', fontsize=12)\n",
    "plt.ylabel('Average Rating (1-5)', fontsize=12)\n",
    "plt.ylim(0, 5)  # Ratings are on a 1-5 scale\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Additional Visualization: Price Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['Price_Clean'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=20, color='red', linestyle='--', linewidth=2, label='£20 Threshold')\n",
    "plt.title('Distribution of Book Prices', fontsize=14)\n",
    "plt.xlabel('Price (£)', fontsize=12)\n",
    "plt.ylabel('Number of Books', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Price_Category', y='Price_Clean', data=df, palette=['#66c2a5', '#fc8d62'])\n",
    "plt.title('Price Distribution by Category', fontsize=14)\n",
    "plt.xlabel('Price Category', fontsize=12)\n",
    "plt.ylabel('Price (£)', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Additional Visualization: Rating Distribution by Category\n",
    "plt.figure(figsize=(10, 6))\n",
    "rating_counts = df.groupby(['Price_Category', 'Rating_Numeric']).size().unstack()\n",
    "rating_counts.plot(kind='bar', stacked=True, color=['#fee08b', '#fc8d59', '#d53e4f', '#9e0142', '#5e4fa2'])\n",
    "plt.title('Rating Distribution by Price Category', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Price Category', fontsize=12)\n",
    "plt.ylabel('Number of Books', fontsize=12)\n",
    "plt.legend(title='Rating', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778064-487a-44de-a0f1-f1503b8933a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the final dataset\n",
    "output_file = 'books_scraped_cleaned.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Data exported to '{output_file}'\")\n",
    "print(f\"✓ Total records: {len(df)}\")\n",
    "\n",
    "# Save a summary statistics file\n",
    "summary_stats = {\n",
    "    'Total_Books': len(df),\n",
    "    'Average_Price': df['Price_Clean'].mean(),\n",
    "    'Median_Price': df['Price_Clean'].median(),\n",
    "    'Affordable_Books': (df['Price_Category'] == 'Affordable').sum(),\n",
    "    'Expensive_Books': (df['Price_Category'] == 'Expensive').sum(),\n",
    "    'Average_Rating_Affordable': df[df['Price_Category'] == 'Affordable']['Rating_Numeric'].mean(),\n",
    "    'Average_Rating_Expensive': df[df['Price_Category'] == 'Expensive']['Rating_Numeric'].mean(),\n",
    "    'Books_In_Stock': df['In_Stock'].sum()\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(list(summary_stats.items()), columns=['Metric', 'Value'])\n",
    "summary_file = 'books_summary_statistics.csv'\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "print(f\"✓ Summary statistics exported to '{summary_file}'\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTotal books analyzed: {len(df)}\")\n",
    "print(f\"Affordable books (< £20): {(df['Price_Clean'] < 20).sum()} ({(df['Price_Clean'] < 20).mean()*100:.1f}%)\")\n",
    "print(f\"Expensive books (≥ £20): {(df['Price_Clean'] >= 20).sum()} ({(df['Price_Clean'] >= 20).mean()*100:.1f}%)\")\n",
    "print(f\"\\nAverage rating - Affordable books: {df[df['Price_Clean'] < 20]['Rating_Numeric'].mean():.2f}\")\n",
    "print(f\"Average rating - Expensive books: {df[df['Price_Clean'] >= 20]['Rating_Numeric'].mean():.2f}\")\n",
    "print(f\"\\nBooks in stock: {df['In_Stock'].sum()} ({(df['In_Stock'].mean()*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d0b91-a6a5-467d-80a6-70dd0efeb2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
